---
title: "warmXtrophic Project: Specific Leaf Area (spla) Analyses"
author: "Phoebe Zarnetske"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

# Load in packages & data
```{r, message = F}
# Clear all existing data
rm(list=ls())

#Load packages
library(tidyverse)
library(bbmle)
library(lmerTest)
library(fitdistrplus) 
library(lme4)
library(car)


# Set ggplot2 plotting
# This code for ggplot2 sets the theme to mostly black and white 
# (Arial font, and large font, base size=24)
theme_set(theme_bw(14))
theme_update(axis.text.x = element_text(size = 12, angle = 90),
             axis.text.y = element_text(size = 12))

# Set working directory to Google Drive
setwd("/Volumes/GoogleDrive/Shared drives/SpaCE_Lab_warmXtrophic/data/")

# Read in data
spla <- read.csv("./L1/SLA/SLA_L1.csv")
```
# Methods for SLA: 
For a subset of species, per site, use scissors to collect 4-5 mature leaves with little to no obvious insect damage or disease off of 3-5 plants of the same species. PICK one representative leaf from the samples of leaves for SLA and place it in a separate glassine envelope or ziploc (for wet surface area and for dry weight later) - place this in a cooler ASAP. This equates to multiple SLA values per plant. As such, "plant_number" should be used as a random effect. If possible, also use "plot" as a random effect (plant_number within plot).
# Check what species are measured at each site
```{r}
unique(spla$species)
with(spla,table(spla$site,spla$species))
with(spla,table(spla$plot,spla$species))
with(spla,table(spla$year,spla$plant_number)) # 2020 has odd entries of letters for plant_number - Chk w Mark
```
Almost all species are only at one site, except Popr. Use species as fixed effect, and site as fixed effect. Plant_number and plot as random effects account for the pseudoreplication of observations within a plant and within a plot.

# Data exploration - some different ways of visualizing these data
```{r}
ggplot(spla, aes(sla, fill = species)) + geom_histogram(binwidth = 50) + 
        facet_grid(year ~ site, margins = TRUE, scales = "free")

ggplot(spla, aes(sla, fill = as.factor(species))) + geom_histogram(binwidth = 50) + 
        facet_grid(species~year, margins = TRUE, scales = "free")

ggplot(spla, aes(sla, fill = species, color=species)) +
        geom_density(alpha = 25)

ggplot(spla, aes(sla, fill = species, color=species)) +
        geom_density(alpha = 25) +
        facet_wrap(~year)

ggplot(spla, aes(sla, fill = species, color=species)) +
        geom_density(alpha = 25) +
        facet_wrap(~year + site)

# Exploring distributions for these right-skewed data:
# See: http://www.di.fc.ul.pt/~jpn/r/distributions/fitting.html
descdist(spla$sla, discrete = FALSE)

# Gamma distribution is an option
fit.gamma <- fitdist(spla$sla, "gamma")
plot(fit.gamma)

# Exponential distribution is another option; not as good but ok
fit.exp <- fitdist(spla$sla, "exp")
plot(fit.exp)

# Lognormal distribution is another option; not as good w Q-Q plot
fit.ln <- fitdist(spla$sla, "lnorm")
plot(fit.ln)

# Square root transformed normal distribution - not as good
fit.sr <- fitdist(sqrt(spla$sla), "norm")
plot(fit.sr)

par(mfrow=c(2,2))
plot.legend <- c("Gamma", "Exponential", "Log Normal")
denscomp(list(fit.gamma, fit.exp, fit.ln), legendtext = plot.legend)
cdfcomp (list(fit.gamma, fit.exp, fit.ln), legendtext = plot.legend)
qqcomp  (list(fit.gamma, fit.exp, fit.ln), legendtext = plot.legend)
ppcomp  (list(fit.gamma, fit.exp, fit.ln), legendtext = plot.legend)

# Goodness of fit comparisons across fits (can't include the sqrt normal bc it becomes diff response values)
gofstat(list(fit.gamma, fit.exp, fit.ln), fitnames = c("Gamma", "Exponential", "Log Normal"))
# Gamma is a winner so far (lowest AIC, BIC), but Lognormal is pretty close. *We will need to re-check this after investigating outliers.*
```


# Determining appropriate distribution in mixed effects model.
See Ben Bolker's site for details on fitting glmms: https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

Fixed effects: warming, year, insecticide
Random effect = plant_number, plot (bc observations are nested within plant and plot)

Fit with ML (REML = FALSE) bc we are interested in estimating fixed effects more than random effects. See https://uoftcoders.github.io/rcourse/lec08-linear-mixed-effects-models.html for more details.
```{r}
m1 <- lmer(log(sla) ~ state + species + year + insecticide + (1 | plot/plant_number), data = spla, REML=FALSE)
ggplot(spla,aes(x=plot,y=log(sla),col=plant_number)) + geom_jitter() + geom_boxplot(alpha=0.2) + facet_wrap(~plant_number)


# Check Assumptions:
# (1) Linearity: if covariates are not categorical (year isn't)
# (2) Homogeneity: Need to Check by plotting residuals vs predicted values.
par(mfrow=c(1,2))
plot(m1, main = "Log Specific Leaf Area (cm2/g)")
# Homogeneity of variance is ok here (increasing variance in resids is not increasing with fitted values)
# Check for homogeneity of variances (true if p>0.05). If the result is not significant, the assumption of equal variances (homoscedasticity) is met (no significant difference between the group variances).
leveneTest(residuals(m1) ~ spla$state)
# Assumption met
leveneTest(residuals(m1) ~ spla$species)
# Assumption not met - not surprising given the differences among species
leveneTest(residuals(m1) ~ spla$insecticide)
# Assumption met
leveneTest(residuals(m1) ~ spla$plot)
# Assumption met

# (3) Normality of error term: need to check by histogram, QQplot of residuals, could do Kolmogorov-Smirnov test.
# Check for normal residuals
qqPlot(resid(m1), main = "Specific Leaf Area (cm2/g)")
hist(residuals(m1), main = "Specific Leaf Area (cm2/g)")
shapiro.test(resid(m1)) # normally distributed resids bc p<0.05
# Outliers from plots above:
spla[1375,]
spla[1406,]
# These are extremely small numbers for area relative to mass; also an order of magnitude lower than other area measurements in 2020.
# Outlier test - yes, these are outliers bc p<0.05 
outlierTest(m1)
# Remove these 2 points
spla1<-spla[-c(1375, 1406),]
m1.1 <- lmer(log(sla) ~ state + species + year + insecticide + (1|plot), data = spla1, REML=FALSE)
qqPlot(resid(m1.1), main = "Specific Leaf Area (cm2/g)")
hist(residuals(m1.1), main = "Specific Leaf Area (cm2/g)")
shapiro.test(resid(m1.1)) # normally distributed resids - still good!
outlierTest(m1.1) # still outliers
spla1[697,] # this data point is an order of magnitude higher for mass (0.164) than similar ones; likely recording error. Edit to appropriate magnitude.
spla1$mass_g[697]=0.0164
spla1[697,] 
spla1[835,] # this data point is an order of magnitude lower for mass (0.0017) than similar ones for Popr with similar area; likely recording error. Edit to appropriate magnitude.
spla1$mass_g[835]=0.017
spla1[835,]

# Re-compute SLA on these data without outliers:
spla1$sla<-spla1$area_cm2/spla1$mass_g

# Re-fit model without outliers
m1.2 <- lmer(log(sla) ~ state + species + year + insecticide + (1|site), data = spla1, REML=FALSE)
qqPlot(resid(m1.2), main = "Specific Leaf Area (cm2/g)")
hist(residuals(m1.2), main = "Specific Leaf Area (cm2/g)")
outlierTest(m1.2) # no outliers (they are all below +-2 resids)

# Check homogeneity of variances again
leveneTest(residuals(m1.2) ~ spla1$state)
# Assumption met bc p>0.05
leveneTest(residuals(m1.2) ~ spla1$species)
# Assumption not met - not surprising given the differences among species
leveneTest(residuals(m1.2) ~ spla1$insecticide)
# Assumption met bc p>0.05
leveneTest(residuals(m1.2) ~ spla1$plot)
# Assumption met bc p>0.05

# (4) Normality of random effect: Get the estimate of random effect (e.g., random intercepts), and check them as you would check the residual. 
require(lme4)
r_int<- ranef(m1.2)$plot$`(Intercept)`
qqnorm(r_int)
qqline(r_int)
shapiro.test(r_int) 
# Yes, normally distributed random effect.

```

*Export* the "no outliers" SLA L1 dataframe as a CSV to ensure it is used for subsequent analyses. This is now the updated csv with the cleaned and merged SLA L0 data, lacking outliers, uploaded to the shared google drive L1 folder:
```{r}
write.csv(spla1, file.path(L1_dir, "./SLA/SLA_L1_nooutliers.csv"), row.names=F)
```

#SUMMARY SO FAR: 
Model exploration from above determined log normal distribution for spla, identified 4 outliers (dropped 2 outliers, and adjusting values in 2 others due to likely measurement error). Proceed with re-checking the distribution and assumptions as above with the outliers removed.
```{r}



```
According to the results above, the outlier removal helps the model meet the assumptions. Proceed with model comparison. Start with investigating the model summary to determine which coviarates to drop.
```{r}
summary(m2)
# Looks like year and warmed aren't significant - I'm leaving it in for now bc the data will change. With fuller data we'd begin model comparison here (will pick up here when those data are available). Then run the code below for diff models:

#AICctab(m2, m3, weights = T)
```

